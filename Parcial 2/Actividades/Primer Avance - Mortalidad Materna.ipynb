{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msite\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_site\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- CSV READER ----------------------------------------------------\n",
    "def import_data(filename):\n",
    "\trows = []\n",
    "\tlabels = []\n",
    "\n",
    "\t# Leo el csv\n",
    "\twith open(filename, 'r') as csvfile:\n",
    "\t    # Creo el csvreader\n",
    "\t\tcsvreader = csv.reader(csvfile)\n",
    "\t    # Salto el header\n",
    "\t\tnext(csvreader, None)\n",
    "\t\t# Salto la linea vacia\n",
    "\t\tnext(csvreader, None)\n",
    "\n",
    "\t\t# Extraigo la informacion de cada fila\n",
    "\t\tfor row in csvreader:\n",
    "\t\t\t# Me quedo con el campo label(Target)\n",
    "\t\t\tlabel = row[369]\n",
    "\t\t\t# Agrego el label al conjunto\n",
    "\t\t\tlabels.append(label)\n",
    "\n",
    "\t\t\t# Me quedo con todos los campos seleccionados en el Analisis de los Datos\n",
    "\t\t\t# ['var15', 'ind_var5', 'ind_var8_0', 'ind_var30', 'num_var5', 'num_var30', 'num_var42', 'var36', 'num_meses_var5_ult3']\n",
    "\t\t\trow = row[1:2] + row[24:25] + row[27:28] + row[63:64] + row[90:91] + \\\n",
    "\t\t\t\trow[138:139] + row[158:159] + row[193:194] + row[280:281]\n",
    "\t\t\t# Agrego la fila al conjunto\n",
    "\t\t\trows.append(row)\n",
    "\n",
    "\t\t\t# Salto la vacia\n",
    "\t\t\tnext(csvreader, None)\n",
    "\n",
    "\treturn rows, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#------------------------------- Definicion Perceptron Multicapa RRNN ------------------------------------------------\n",
    "\n",
    "# Parámetros usados para entrenar la red\n",
    "learning_rate = 0.03 #tasa de aprendizaje\n",
    "num_steps = 3000 #cantidad de pasos de entrenamiento\n",
    "batch_size = 1000 #cantidad de ejemplos por paso\n",
    "\n",
    "# Parámetros para la construcción de la red\n",
    "n_hidden = 4 # número de neuronas en la capa oculta\n",
    "num_classes = 2 # 2 clases: 0 - Satisfecho y  1 - Insatisfecho\n",
    "\n",
    "# Definimos la red neuronal\n",
    "def neural_net (x_dict):\n",
    "\t# x_dic es un diccionario con los valores de entrada\n",
    "\t# x serán los valores de entrada de los campos\n",
    "\tx = x_dict['data'] #en particular vendrán en el campo \"data\"\n",
    "\t# Conectamos x (la entrada) con la capa oculta: Conexión full\n",
    "\tlayer_1 = tf.layers.dense(x, n_hidden)\n",
    "\t# Conectamos la capa oculta con la capa de salida\n",
    "\tout_layer = tf.layers.dense(layer_1, num_classes)\n",
    "\treturn out_layer\n",
    "\n",
    "# Usamos la clase “TF Estimator Template”, para definir cómo será el entrenamiento\n",
    "def model_fn (features, labels, mode):\n",
    "\t# Llamamos a la función anterior para construir la red\n",
    "\tlogits = neural_net(features)\n",
    "\n",
    "\t# Predicciones\n",
    "\tpred_classes = tf.argmax(logits, axis=1)\n",
    "\tpred_probas = tf.nn.softmax(logits)\n",
    "\n",
    "\t# Si es de predicción devolvemos directamente un EstimatorSpec\n",
    "\tif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "\t\treturn tf.estimator.EstimatorSpec(mode, predictions = pred_classes)\n",
    "\n",
    "\t# Definimos nuestro error\n",
    "\tloss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "\t# sparse_softmax_cross_entropy_with_logits : Mide el error de probabilidad\n",
    "\t# en tareas de clasificación discretas en las que las clases son mutuamente\n",
    "\t# excluyentes (cada entrada está en exactamente una clase)\n",
    "\t# reduce_mean : Calcula la media de los elementos a través de las dimensiones de un tensor\n",
    "\n",
    "\t#Definimos un optmizador, que trabaja por el método de descenso por gradiente\n",
    "\toptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "\ttrain_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "\n",
    "\t# Definimos cómo se evaluará la precisión del modelo\n",
    "\tacc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "\t# Finalmente devolvemos un objeto: “EstimatorSpec”, indicando todo lo que\n",
    "\t# calculamos para el entrenamiento: modo, predicción, error (loss), método de entrenamiento y métricas\n",
    "\testim_specs = tf.estimator.EstimatorSpec(mode=mode, predictions=pred_classes, loss=loss_op, train_op=train_op, eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "\treturn estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comienza el programa\n",
    "print(\"Comienza el programa...\")\n",
    "# ------------------- Obtengo los datos de entrenamiento y evaluacion ---------------------------------------------------------------\n",
    "print(\"Obteniendo datos de entrenamiento del archivo process-train.csv...\")\n",
    "filename = \"process-train.csv\"\n",
    "rowsTrain, labelsTrain = import_data(filename)\n",
    "print(\"Datos de entrenamiento OK\")\n",
    "\n",
    "print(\"Partiendo el conjunto de entrenamiento en entrenamiento y evaluacion...\")\n",
    "# Transformo rows y labels en np array\n",
    "train_data_np = np.asarray(rowsTrain, np.float32)\n",
    "train_labels_np = np.asarray(labelsTrain, np.int32)\n",
    "\n",
    "# Finalmente partimos el conjunto en 0.7 para entrenamiento y 0.3 para testing.\n",
    "trainX, testX, trainY, testY = train_test_split(\n",
    "    train_data_np, train_labels_np, test_size=0.30)\n",
    "\n",
    "print(\"Datos de entrenamiento y evaluacion OK\")\n",
    "\n",
    "# ----------------------- Entrenamiento de la Red Neuronal --------------------------------------------------------------\n",
    "print(\"Entrenamiento de la red neuronal...\")\n",
    "# Construimos un estimador, le decimos que use la función antes definida\n",
    "model = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "# Pasamos ahora todos los parámetros que necesita la función definida\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'data': trainX}, y=trainY, batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.train(input_fn, steps=num_steps)\n",
    "print(\"Entrenamiento OK\")\n",
    "\n",
    "# ----------------------- Evaluación del modelo de la Red Neuronal --------------------------------------------------------------\n",
    "print(\"Evaluación de la red neuronal...\")\n",
    "# Evaluamos el modelo\n",
    "# Definimos la entrada para evaluar\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'data': testX}, y=testY, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Usamos el método 'evaluate'del modelo\n",
    "eTrain = model.evaluate(input_fn)\n",
    "print(\"Evaluación del modelo OK\")\n",
    "\n",
    "# ------------------- Obtengo los datos de prueba ---------------------------------------------------------------\n",
    "print(\"Obteniendo datos de prueba del archivo process-test.csv...\")\n",
    "filename = \"process-test.csv\"\n",
    "rowsTest, labelsTest = import_data(filename)\n",
    "\n",
    "# Transformo rows y labels en np array\n",
    "test_data_np = np.asarray(rowsTest, np.float32)\n",
    "test_labels_np = np.asarray(labelsTest, np.int32)\n",
    "\n",
    "print(\"Datos de prueba OK\")\n",
    "\n",
    "# ----------------------- Prueba de la Red Neuronal --------------------------------------------------------------\n",
    "print(\"Prueba de la red neuronal...\")\n",
    "# Probamos el modelo\n",
    "# Definimos la entrada para evaluar\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'data': test_data_np}, y=test_labels_np, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Usamos el método 'evaluate'del modelo\n",
    "eTest = model.evaluate(input_fn)\n",
    "print(\"Prueba del modelo OK\")\n",
    "\n",
    "# ----------------------- Resultados --------------------------------------------------------------\n",
    "print(\"--------- Resultados Obtenidos ---------- (los valores se encutran en %)\")\n",
    "print(\"Precisión en la evaluacion del modelo: \", (eTrain['accuracy'] * 100))\n",
    "print(\"Precisión en la prueba del modelo: \", (eTest['accuracy'] * 100))\n",
    "print(\"Programa Finalizado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
